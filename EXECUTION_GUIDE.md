# ğŸš€ Guia Passo a Passo - ExecuÃ§Ã£o do Projeto

Este documento explica a **ordem correta de execuÃ§Ã£o** do projeto Payment Fraud Detection, desde a instalaÃ§Ã£o atÃ© a produÃ§Ã£o.

---

## ğŸ“‹ Ãndice

1. [InstalaÃ§Ã£o Inicial](#1-instalaÃ§Ã£o-inicial)
2. [PreparaÃ§Ã£o dos Dados](#2-preparaÃ§Ã£o-dos-dados)
3. [ExploraÃ§Ã£o Inicial (Opcional)](#3-exploraÃ§Ã£o-inicial-opcional)
4. [Pipeline Completo de Treinamento](#4-pipeline-completo-de-treinamento)
5. [AnÃ¡lise Cold Start (Opcional)](#5-anÃ¡lise-cold-start-opcional)
6. [Fazer PrediÃ§Ãµes](#6-fazer-prediÃ§Ãµes)
7. [Deploy para ProduÃ§Ã£o](#7-deploy-para-produÃ§Ã£o)

---

## 1. InstalaÃ§Ã£o Inicial

### Passo 1.1: Clonar/Extrair o Projeto

```bash
# Se baixou o .tar.gz
tar -xzf payment-fraud-detection-final.tar.gz
cd payment-fraud-detection

# Ou se clonou do GitHub
git clone https://github.com/seu-usuario/payment-fraud-detection.git
cd payment-fraud-detection
```

### Passo 1.2: Criar Ambiente Virtual

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# No Linux/Mac:
source venv/bin/activate

# No Windows:
venv\Scripts\activate
```

### Passo 1.3: Instalar DependÃªncias

```bash
# Atualizar pip
pip install --upgrade pip

# Instalar dependÃªncias do projeto
pip install -r requirements.txt

# (Opcional) Para desenvolvimento:
pip install -r requirements-dev.txt
```

### Passo 1.4: Verificar InstalaÃ§Ã£o

```bash
# Verificar se o pacote foi instalado corretamente
python -c "import src; print('âœ… InstalaÃ§Ã£o OK!')"

# Verificar versÃµes importantes
python -c "import sklearn, xgboost, pandas; print('âœ… DependÃªncias OK!')"
```

**âœ… Checkpoint**: Se nÃ£o houver erros, prossiga para o prÃ³ximo passo.

---

## 2. PreparaÃ§Ã£o dos Dados

### Passo 2.1: Organizar Seus Dados

Coloque seu arquivo de transaÃ§Ãµes em `data/raw/`:

```bash
# Estrutura esperada do arquivo:
data/raw/df.xlsx  # ou .csv, .parquet
```

**Colunas ObrigatÃ³rias:**
```
- transaction_id      (str/int)
- transaction_date    (datetime)
- transaction_amount  (float)
- user_id            (str/int)
- merchant_id        (str/int)
- device_id          (str/int, pode ter NaN)
- has_cbk            (int: 0 ou 1)
```

### Passo 2.2: Validar Dados (Opcional mas Recomendado)

```bash
# Script de validaÃ§Ã£o rÃ¡pida
python -c "
from src.data_loader import load_data, validate_data

# Carregar dados
df = load_data('data/raw/df.xlsx')
print(f'âœ… Dados carregados: {len(df)} transaÃ§Ãµes')

# Validar
diag = validate_data(df)
print(f'âœ… Taxa de fraude: {diag[\"fraud_rate\"]*100:.2f}%')
print(f'âœ… Device faltando: {diag[\"missing_device_rate\"]*100:.1f}%')
"
```

**âœ… Checkpoint**: Dados carregados sem erros? Continue!

---

## 3. ExploraÃ§Ã£o Inicial (Opcional)

### Passo 3.1: AnÃ¡lise ExploratÃ³ria RÃ¡pida

Se quiser entender melhor seus dados antes de treinar:

```bash
# Usando o script original (anÃ¡lise completa)
python notebooks/fraud_detection_original.py
```

**O que isso faz:**
- Gera grÃ¡ficos de distribuiÃ§Ã£o
- Analisa padrÃµes temporais
- Cria features iniciais
- Salva visualizaÃ§Ãµes em `outputs/eda/`

**SaÃ­das:**
- `outputs/eda/eda_transaction_amount.png`
- `outputs/eda/temporal_patterns.png`

### Passo 3.2: Revisar Outputs da EDA

```bash
# Ver os grÃ¡ficos gerados
ls -la outputs/eda/

# No Linux com interface grÃ¡fica:
xdg-open outputs/eda/eda_transaction_amount.png

# No Mac:
open outputs/eda/eda_transaction_amount.png

# No Windows:
start outputs/eda/eda_transaction_amount.png
```

---

## 4. Pipeline Completo de Treinamento

### Passo 4.1: Executar Pipeline Principal (BÃ¡sico)

Este Ã© o **comando mais importante** do projeto:

```bash
python src/main.py \
    --data data/raw/df.xlsx \
    --output outputs/
```

**O que acontece:**
1. âœ… Carrega e valida dados
2. âœ… Divide train/test (80/20)
3. âœ… Cria 25 features automaticamente
4. âœ… Treina 4 modelos (LogReg, RF, XGBoost, MLP)
5. âœ… Avalia performance
6. âœ… Gera visualizaÃ§Ãµes (ROC, PR, confusion matrices)
7. âœ… Salva modelos treinados

**Tempo estimado:** 2-5 minutos (depende do tamanho dos dados)

### Passo 4.2: Executar com OtimizaÃ§Ã£o (AvanÃ§ado)

Para melhores resultados (mais lento):

```bash
python src/main.py \
    --data data/raw/df.xlsx \
    --output outputs/ \
    --optimize
```

**O que muda:**
- Usa Bayesian Optimization para Random Forest
- Testa diferentes hiperparÃ¢metros
- **Tempo:** 10-30 minutos

### Passo 4.3: Executar Sem VisualizaÃ§Ãµes (Mais RÃ¡pido)

Se quiser apenas treinar modelos:

```bash
python src/main.py \
    --data data/raw/df.xlsx \
    --output outputs/ \
    --skip-viz
```

**Economia:** ~30% mais rÃ¡pido

### Passo 4.4: Revisar Resultados

```bash
# Ver comparaÃ§Ã£o de modelos
cat outputs/tables/model_comparison.csv

# Ver estrutura de arquivos gerados
ls -la outputs/
```

**Arquivos gerados:**

```
outputs/
â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ transaction_amount_distribution.png  ğŸ“Š Histograma + boxplot
â”‚   â”œâ”€â”€ fraud_rate_by_hour.png              ğŸ“ˆ Fraude por hora
â”‚   â””â”€â”€ fraud_rate_by_day.png               ğŸ“ˆ Fraude por dia da semana
â”œâ”€â”€ tables/
â”‚   â””â”€â”€ model_comparison.csv                 ğŸ“Š MÃ©tricas dos modelos
â”œâ”€â”€ curves/
â”‚   â”œâ”€â”€ roc_curves.png                       ğŸ“ˆ Curvas ROC
â”‚   â”œâ”€â”€ pr_curves.png                        ğŸ“ˆ Precision-Recall
â”‚   â””â”€â”€ cost_sensitivity.png                 ğŸ’° AnÃ¡lise de custo
â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ LogReg_cm.png                        ğŸ”¢ Logistic Regression
â”‚   â”œâ”€â”€ RF_cm.png                            ğŸ”¢ Random Forest
â”‚   â”œâ”€â”€ XGBoost_cm.png                       ğŸ”¢ XGBoost
â”‚   â””â”€â”€ MLP_cm.png                           ğŸ”¢ MLP Neural Network
â”œâ”€â”€ shap/
â”‚   â”œâ”€â”€ shap_bar_top10.png                   ğŸ” Feature importance
â”‚   â””â”€â”€ shap_beeswarm_top10.png              ğŸ” DistribuiÃ§Ã£o SHAP
â””â”€â”€ models/
    â””â”€â”€ fraud_detection_pipeline.pkl         ğŸ¤– Modelo treinado

data/
â””â”€â”€ processed/
    â”œâ”€â”€ train_features.csv                   ğŸ’¾ Features de treino
    â””â”€â”€ test_features.csv                    ğŸ’¾ Features de teste
```

**âœ… Checkpoint**: Pipeline executou sem erros? Modelos salvos? Continue!

---

## 5. AnÃ¡lise Cold Start (Opcional)

### Passo 5.1: Executar Pipeline Cold Start

Para analisar performance em usuÃ¡rios novos:

```bash
python src/cold_start.py \
    --data data/raw/df.xlsx \
    --output outputs/
```

**O que faz:**
1. Identifica transaÃ§Ãµes "cold start" (novos usuÃ¡rios/merchants)
2. Treina modelo especializado
3. Compara performance: cold vs. non-cold
4. Gera relatÃ³rios segmentados

**SaÃ­das:**
- `outputs/tables/segmented_coldstart_metrics.csv`
- `outputs/tables/cold_start_rows_scored.csv`
- `outputs/tables/non_cold_start_rows_scored.csv`

### Passo 5.2: Analisar Resultados

```bash
# Ver mÃ©tricas segmentadas
cat outputs/tables/segmented_coldstart_metrics.csv

# Ver quais transaÃ§Ãµes foram classificadas como cold start
head outputs/tables/cold_start_rows_scored.csv
```

---

## 6. Fazer PrediÃ§Ãµes

### Passo 6.1: PrediÃ§Ã£o em Lote (Batch)

Para prever fraude em novas transaÃ§Ãµes:

**MÃ©todo 1: Via Script Python**

```python
# Criar arquivo: predict.py
from src.models import FraudDetectionPipeline
from src.feature_engineering import FeatureEngineer
from src.data_loader import load_data, prepare_data
import pandas as pd

# 1. Carregar modelo treinado
pipeline = FraudDetectionPipeline.load('outputs/models/fraud_detection_pipeline.pkl')

# 2. Carregar novos dados
new_data = load_data('data/raw/new_transactions.xlsx')
new_data = prepare_data(new_data)

# 3. Engenharia de features (precisa do engineer treinado)
# Nota: VocÃª precisa salvar o engineer junto com o pipeline
# Por enquanto, retreine ou use pipeline completo

# 4. Fazer prediÃ§Ãµes
predictions = pipeline.predict(new_data)
probabilities = pipeline.predict_proba(new_data)

# 5. Adicionar resultados ao dataframe
new_data['fraud_prediction'] = predictions
new_data['fraud_probability'] = probabilities

# 6. Salvar resultados
new_data.to_csv('outputs/predictions.csv', index=False)

print(f"âœ… PrediÃ§Ãµes concluÃ­das!")
print(f"   Frauds detectadas: {predictions.sum()} de {len(predictions)}")
print(f"   Taxa de fraude: {predictions.mean()*100:.2f}%")
```

Execute:
```bash
python predict.py
```

### Passo 6.2: PrediÃ§Ã£o Interativa (Python REPL)

```bash
python
```

```python
from src.models import FraudDetectionPipeline
import pandas as pd

# Carregar modelo
pipeline = FraudDetectionPipeline.load('outputs/models/fraud_detection_pipeline.pkl')

# Criar transaÃ§Ã£o de teste
transaction = pd.DataFrame({
    'transaction_amount': [1500.0],
    'hour': [23],
    'day_of_week': [5],
    'merchant_id_cbk_rate': [0.15],
    'device_id_cbk_rate': [0.05],
    'user_id_cbk_rate': [0.02],
    # ... adicionar todas as 25 features
})

# Prever
prob = pipeline.predict_proba(transaction)[0]
pred = pipeline.predict(transaction)[0]

print(f"Probabilidade de fraude: {prob*100:.2f}%")
print(f"PrediÃ§Ã£o: {'FRAUDE' if pred else 'LEGÃTIMA'}")
```

---

## 7. Deploy para ProduÃ§Ã£o

### Passo 7.1: Criar API REST (FastAPI)

```bash
# Instalar FastAPI
pip install fastapi uvicorn

# Criar arquivo de API (jÃ¡ existe exemplo no deployment_guide.md)
# Use o cÃ³digo em docs/deployment_guide.md seÃ§Ã£o "Option 2: Real-Time API"
```

### Passo 7.2: Executar API Localmente

```bash
# Rodar servidor de desenvolvimento
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

### Passo 7.3: Testar API

```bash
# Em outro terminal, testar endpoint
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "transaction_id": "test_001",
    "transaction_amount": 1500.0,
    "user_id": "user_123",
    "merchant_id": "merchant_456",
    "device_id": "device_789",
    "transaction_date": "2024-01-28T15:30:00"
  }'
```

### Passo 7.4: Deploy para ProduÃ§Ã£o

Siga o guia completo em `docs/deployment_guide.md` para:
- Docker
- Kubernetes
- Cloud (AWS/GCP/Azure)
- Monitoring

---

## ğŸ“Š Ordem de ExecuÃ§Ã£o Resumida

### Primeira Vez (Setup Completo)

```bash
# 1. Setup inicial
cd payment-fraud-detection
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Preparar dados
# Coloque df.xlsx em data/raw/

# 3. Treinar modelos
python src/main.py --data data/raw/df.xlsx --output outputs/

# 4. Revisar resultados
cat outputs/tables/model_comparison.csv
```

### Uso DiÃ¡rio (PrediÃ§Ãµes)

```bash
# 1. Ativar ambiente
source venv/bin/activate

# 2. Fazer prediÃ§Ãµes
python predict.py  # seu script customizado

# 3. Revisar resultados
cat outputs/predictions.csv
```

### Retreinamento Mensal

```bash
# 1. Ativar ambiente
source venv/bin/activate

# 2. Retreinar com dados atualizados
python src/main.py \
    --data data/raw/df_2024_02.xlsx \
    --output outputs/retrain/ \
    --optimize

# 3. Validar novo modelo
python scripts/validate_model.py  # criar esse script

# 4. Substituir modelo em produÃ§Ã£o
cp outputs/retrain/models/fraud_detection_pipeline.pkl \
   outputs/models/fraud_detection_pipeline.pkl
```

---

## ğŸ› Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'src'"

**SoluÃ§Ã£o:**
```bash
pip install -e .
```

### Erro: "File not found: data/raw/df.xlsx"

**SoluÃ§Ã£o:**
```bash
# Verificar caminho
ls -la data/raw/
# Ajustar comando
python src/main.py --data /caminho/completo/para/df.xlsx
```

### Erro: "Memory Error"

**SoluÃ§Ã£o:**
```bash
# Reduzir complexidade do modelo em config.json
{
  "models": {
    "random_forest": {
      "n_estimators": 100  # reduzir de 300
    }
  }
}
```

### Performance Lenta

**SoluÃ§Ã£o:**
```bash
# Usar menos otimizaÃ§Ã£o
python src/main.py --data data/raw/df.xlsx --skip-viz
```

### VisualizaÃ§Ãµes NÃ£o Foram Geradas

**SoluÃ§Ã£o:**
```bash
# 1. Verificar se as pastas existem
mkdir -p outputs/{eda,confusion_matrices,curves,shap,tables,models}

# 2. NÃƒO usar --skip-viz
python src/main.py --data data/raw/df.xlsx --output outputs/

# 3. Verificar dependÃªncias
pip install matplotlib seaborn shap

# 4. Ver guia completo
cat VISUALIZATION_TROUBLESHOOTING.md
```

---

## âœ… Checklist de ExecuÃ§Ã£o

Use este checklist para garantir que executou tudo corretamente:

- [ ] Ambiente virtual criado e ativado
- [ ] DependÃªncias instaladas (`requirements.txt`)
- [ ] Dados em `data/raw/df.xlsx` (ou similar)
- [ ] Pipeline principal executado (`src/main.py`)
- [ ] Resultados gerados em `outputs/`
- [ ] Modelo salvo em `outputs/models/`
- [ ] MÃ©tricas revisadas (`model_comparison.csv`)
- [ ] (Opcional) Pipeline cold start executado
- [ ] (Opcional) API testada localmente
- [ ] (Opcional) Deploy para produÃ§Ã£o

---

## ğŸ¯ Fluxo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. INSTALAÃ‡ÃƒO  â”‚
â”‚  pip install    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. PREPARAÃ‡ÃƒO  â”‚
â”‚  data/raw/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. TREINAMENTO â”‚
â”‚  src/main.py    â”‚â—„â”€â”€â”€ Loop de otimizaÃ§Ã£o (opcional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. VALIDAÃ‡ÃƒO   â”‚
â”‚  Ver outputs/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5a. PREDIÃ‡Ã•ES  â”‚  â”‚  5b. COLD START â”‚
â”‚  predict.py     â”‚  â”‚  cold_start.py  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  6. PRODUÃ‡ÃƒO    â”‚
           â”‚  API / Docker   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Suporte

Se encontrar problemas:
1. Verifique os logs em `fraud_detection.log`
2. Consulte `QUICKSTART.md` para problemas comuns
3. Leia `docs/deployment_guide.md` para produÃ§Ã£o
4. Abra issue no GitHub

**Bom trabalho! ğŸš€**
